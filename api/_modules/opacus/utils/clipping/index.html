<!DOCTYPE html><html lang="en"><head><meta charSet="utf-8"/><meta http-equiv="X-UA-Compatible" content="IE=edge"/><title>Opacus · Train PyTorch models with Differential Privacy</title><meta name="viewport" content="width=device-width"/><meta name="generator" content="Docusaurus"/><meta name="description" content="Train PyTorch models with Differential Privacy"/><meta name="docsearch:language" content="en"/><meta property="og:title" content="Opacus · Train PyTorch models with Differential Privacy"/><meta property="og:type" content="website"/><meta property="og:url" content="https://opacus.ai/"/><meta property="og:description" content="Train PyTorch models with Differential Privacy"/><meta property="og:image" content="https://opacus.ai/img/opacus_logo.svg"/><meta name="twitter:card" content="summary"/><meta name="twitter:image" content="https://opacus.ai/img/opacus_logo.svg"/><link rel="shortcut icon" href="/img/opacus_favicon.svg"/><link rel="stylesheet" href="https://cdn.jsdelivr.net/docsearch.js/1/docsearch.min.css"/><link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/default.min.css"/><script>
              (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
              (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
              m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
              })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

              ga('create', 'UA-117752657-3', 'auto');
              ga('send', 'pageview');
            </script><link rel="stylesheet" href="/css/code_block_buttons.css"/><script type="text/javascript" src="https://buttons.github.io/buttons.js"></script><script type="text/javascript" src="/js/code_block_buttons.js"></script><script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.0/clipboard.min.js"></script><script type="text/javascript" src="/js/mathjax.js"></script><script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-AMS_HTML"></script><script src="https://unpkg.com/vanilla-back-to-top@7.1.14/dist/vanilla-back-to-top.min.js"></script><script>
        document.addEventListener('DOMContentLoaded', function() {
          addBackToTop(
            {"zIndex":100}
          )
        });
        </script><script src="/js/scrollSpy.js"></script><link rel="stylesheet" href="/css/main.css"/><script src="/js/codetabs.js"></script></head><body><div class="fixedHeaderContainer"><div class="headerWrapper wrapper"><header><a href="/"><img class="logo" src="/img/opacus_logo.svg" alt="Opacus"/></a><div class="navigationWrapper navigationSlider"><nav class="slidingNav"><ul class="nav-site nav-site-internal"><li class=""><a href="/docs/introduction" target="_self">Introduction</a></li><li class=""><a href="/docs/faq" target="_self">FAQ</a></li><li class=""><a href="/tutorials/" target="_self">Tutorials</a></li><li class=""><a href="/api/" target="_self">API Reference</a></li><li class=""><a href="https://github.com/pytorch/opacus" target="_self">GitHub</a></li><li class="navSearchWrapper reactNavSearchWrapper"><input type="text" id="search_input_react" placeholder="Search" title="Search"/></li></ul></nav></div></header></div></div><div class="navPusher"><div>
<script type="text/javascript" id="documentation_options" data-url_root="./"
  src="/js/documentation_options.js"></script>
<script type="text/javascript" src="/js/jquery.js"></script>
<script type="text/javascript" src="/js/underscore.js"></script>
<script type="text/javascript" src="/js/doctools.js"></script>
<script type="text/javascript" src="/js/language_data.js"></script>
<script type="text/javascript" src="/js/searchtools.js"></script>
<div class="sphinx"><div class="document">
<div class="documentwrapper">
<div class="bodywrapper">
<div class="body" role="main">
<h1>Source code for opacus.utils.clipping</h1><div class="highlight"><pre>
<span></span><span class="ch">#!/usr/bin/env python3</span>
<span class="c1"># Copyright (c) Facebook, Inc. and its affiliates. All Rights Reserved</span>

<span class="kn">import</span> <span class="nn">math</span>
<span class="kn">from</span> <span class="nn">abc</span> <span class="kn">import</span> <span class="n">ABC</span>
<span class="kn">from</span> <span class="nn">enum</span> <span class="kn">import</span> <span class="n">IntEnum</span>
<span class="kn">from</span> <span class="nn">itertools</span> <span class="kn">import</span> <span class="n">cycle</span>
<span class="kn">from</span> <span class="nn">typing</span> <span class="kn">import</span> <span class="n">Iterator</span><span class="p">,</span> <span class="n">List</span><span class="p">,</span> <span class="n">Union</span>

<span class="kn">import</span> <span class="nn">torch</span>


<span class="k">try</span><span class="p">:</span>
    <span class="kn">from</span> <span class="nn">skimage.filters</span> <span class="kn">import</span> <span class="n">threshold_otsu</span> <span class="k">as</span> <span class="n">otsu</span>
<span class="k">except</span> <span class="ne">ImportError</span><span class="p">:</span>

    <span class="k">def</span> <span class="nf">otsu</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">float</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span><span class="s2">"Install skimage!"</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">_mean_plus_r_var</span><span class="p">(</span><span class="n">data</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">ratio</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">float</span><span class="p">:</span>
    <span class="sd">"""</span>
<span class="sd">    Caclulates mean + ratio x standard_deviation of the provided tensor</span>
<span class="sd">    and returns the larger of this value and the smallest element in</span>
<span class="sd">    the tensor (can happen when ratio is negative).</span>

<span class="sd">    Args:</span>
<span class="sd">        data: Pytorch tensor containing the data on which the mean and stdv.</span>
<span class="sd">            is evaluated.</span>
<span class="sd">        ratio: Value of the scaling factor in the value calculated by the</span>
<span class="sd">            function.</span>

<span class="sd">    Returns:</span>
<span class="sd">        The result of the function.</span>

<span class="sd">    """</span>
    <span class="k">return</span> <span class="nb">max</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">min</span><span class="p">()</span><span class="o">.</span><span class="n">item</span><span class="p">(),</span> <span class="n">data</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span><span class="o">.</span><span class="n">item</span><span class="p">()</span> <span class="o">+</span> <span class="n">ratio</span> <span class="o">*</span> <span class="n">data</span><span class="o">.</span><span class="n">std</span><span class="p">()</span><span class="o">.</span><span class="n">item</span><span class="p">()</span> <span class="o">+</span> <span class="mf">1e-8</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">_pvalue</span><span class="p">(</span><span class="n">data</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">ratio</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.25</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
    <span class="sd">"""</span>
<span class="sd">    Finds the pth largest value in the tensor, where p = ratio x len(data).</span>

<span class="sd">    Args:</span>
<span class="sd">        data: Pytorch tensor against which the function is evaluated.</span>
<span class="sd">        ratio: Value of the scaling factor in the value calculated by</span>
<span class="sd">            the function.</span>

<span class="sd">    Returns:</span>
<span class="sd">        Tensor of dimension ``(1,)`` with the result of the function.</span>
<span class="sd">    """</span>
    <span class="n">cut</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="nb">int</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">numel</span><span class="p">()</span> <span class="o">*</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">ratio</span><span class="p">)))</span>
    <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">kthvalue</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">cut</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>


<span class="k">def</span> <span class="nf">_static</span><span class="p">(</span><span class="n">data</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">current_thresh</span><span class="p">:</span> <span class="nb">float</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">float</span><span class="p">:</span>
    <span class="sd">"""</span>
<span class="sd">    Passes through the specified input ``current_threshold``.</span>

<span class="sd">    Args:</span>
<span class="sd">        data: Pytorch tensor containing the data.</span>
<span class="sd">        current_thresh: The threshold value.</span>

<span class="sd">    Returns:</span>
<span class="sd">        The threshold value.</span>
<span class="sd">    """</span>
    <span class="k">return</span> <span class="n">current_thresh</span>


<span class="k">def</span> <span class="nf">_otsu</span><span class="p">(</span><span class="n">data</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">float</span><span class="p">:</span>
    <span class="sd">"""</span>
<span class="sd">    Returns an intensity threshold for an image that separates it</span>
<span class="sd">    into backgorund and foreground pixels.</span>

<span class="sd">    The implementation uses Otsu's method, which assumes a GMM with</span>
<span class="sd">    2 components but uses some heuristic to maximize the variance</span>
<span class="sd">    differences. The input data is shaped into a 2D image for the</span>
<span class="sd">    purpose of evaluating the threshold value.</span>

<span class="sd">    Args:</span>
<span class="sd">        data: Pytorch tensor containing the data.</span>

<span class="sd">    Returns:</span>
<span class="sd">        Threshold value determined via Otsu's method.</span>
<span class="sd">    """</span>
    <span class="n">h</span> <span class="o">=</span> <span class="mi">2</span> <span class="o">**</span> <span class="nb">int</span><span class="p">(</span><span class="mi">1</span> <span class="o">+</span> <span class="n">math</span><span class="o">.</span><span class="n">log2</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span> <span class="o">/</span> <span class="mi">2</span><span class="p">)</span>
    <span class="n">fake_img</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">h</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
    <span class="k">return</span> <span class="n">otsu</span><span class="p">(</span><span class="n">fake_img</span><span class="p">,</span> <span class="n">h</span><span class="p">)</span>


<div class="viewcode-block" id="ClippingMethod"><a class="viewcode-back" href="../../../clipping.html#opacus.utils.clipping.ClippingMethod">[docs]</a><span class="k">class</span> <span class="nc">ClippingMethod</span><span class="p">(</span><span class="n">IntEnum</span><span class="p">):</span>
    <span class="n">STATIC</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">PVALUE</span> <span class="o">=</span> <span class="mi">1</span>
    <span class="n">MEAN</span> <span class="o">=</span> <span class="mi">2</span>
    <span class="n">GMM</span> <span class="o">=</span> <span class="mi">3</span>
    <span class="n">OTSU</span> <span class="o">=</span> <span class="mi">4</span></div>


<span class="n">_thresh_</span> <span class="o">=</span> <span class="p">{</span>
    <span class="n">ClippingMethod</span><span class="o">.</span><span class="n">STATIC</span><span class="p">:</span> <span class="n">_static</span><span class="p">,</span>
    <span class="n">ClippingMethod</span><span class="o">.</span><span class="n">PVALUE</span><span class="p">:</span> <span class="n">_pvalue</span><span class="p">,</span>
    <span class="n">ClippingMethod</span><span class="o">.</span><span class="n">MEAN</span><span class="p">:</span> <span class="n">_mean_plus_r_var</span><span class="p">,</span>
    <span class="n">ClippingMethod</span><span class="o">.</span><span class="n">OTSU</span><span class="p">:</span> <span class="n">_otsu</span><span class="p">,</span>
<span class="p">}</span>


<span class="k">def</span> <span class="nf">_calculate_thresh_value</span><span class="p">(</span>
    <span class="n">data</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
    <span class="n">current_thresh</span><span class="p">:</span> <span class="nb">float</span><span class="p">,</span>
    <span class="n">clipping_mehod</span><span class="p">:</span> <span class="n">ClippingMethod</span> <span class="o">=</span> <span class="n">ClippingMethod</span><span class="o">.</span><span class="n">STATIC</span><span class="p">,</span>
    <span class="n">ratio</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">float</span><span class="p">:</span>
    <span class="sd">"""</span>
<span class="sd">    Calculates a clipping threshold by looking at the layer norms</span>
<span class="sd">    of each example.</span>

<span class="sd">    Four methods are supported: static threshold, threshold calculated</span>
<span class="sd">    based on mean and variance of the norms, and threshold calculated</span>
<span class="sd">    based on percentile values of the norms.</span>

<span class="sd">    Args:</span>
<span class="sd">        data: Pytorch tensor containing the data</span>
<span class="sd">        current_thresh: Value of the current threshold.</span>
<span class="sd">        clipping_method: Enum value defining the clipping strategy. Current</span>
<span class="sd">            options are STATIC, PVALUE, MEAN, and OTSU.</span>
<span class="sd">        ratio: Value that has different meaning for differnet strategies, it</span>
<span class="sd">            is the percentile parameter for PVALUE, and a multiplier for</span>
<span class="sd">            standard deviation for MEAN. It has no significance for OTSU and</span>
<span class="sd">            STATIC.</span>

<span class="sd">    Returns:</span>
<span class="sd">        Clipping threshold value</span>
<span class="sd">    """</span>
    <span class="k">return</span> <span class="n">_thresh_</span><span class="p">[</span><span class="n">clipping_mehod</span><span class="p">](</span><span class="n">data</span><span class="p">,</span> <span class="n">ratio</span><span class="o">=</span><span class="n">ratio</span><span class="p">,</span> <span class="n">current_thresh</span><span class="o">=</span><span class="n">current_thresh</span><span class="p">)</span>


<div class="viewcode-block" id="NormClipper"><a class="viewcode-back" href="../../../clipping.html#opacus.utils.clipping.NormClipper">[docs]</a><span class="k">class</span> <span class="nc">NormClipper</span><span class="p">(</span><span class="n">ABC</span><span class="p">):</span>
    <span class="sd">"""</span>
<span class="sd">    An abstract class to calculate the clipping factor</span>
<span class="sd">    """</span>

<div class="viewcode-block" id="NormClipper.calc_clipping_factors"><a class="viewcode-back" href="../../../clipping.html#opacus.utils.clipping.NormClipper.calc_clipping_factors">[docs]</a>    <span class="k">def</span> <span class="nf">calc_clipping_factors</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">norms</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Union</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">],</span> <span class="n">Iterator</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]]:</span>
        <span class="sd">"""</span>
<span class="sd">        Calculates the clipping factor(s) based on the given</span>
<span class="sd">        parameters. A concrete subclass must implement this.</span>

<span class="sd">        Returns:</span>
<span class="sd">            The clipping factors</span>
<span class="sd">        """</span>
        <span class="k">pass</span></div>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">thresholds</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
        <span class="sd">"""</span>
<span class="sd">        Depending on the type of clipper, returns threshold values.</span>

<span class="sd">        Returns:</span>
<span class="sd">            The threshold values</span>
<span class="sd">        """</span>
        <span class="k">pass</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">is_per_layer</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">bool</span><span class="p">:</span>
        <span class="sd">"""</span>
<span class="sd">        Depending on type of clipper, returns indicator as to whether</span>
<span class="sd">        different clipping is applied to each layer in the model.</span>

<span class="sd">        Returns:</span>
<span class="sd">            Flag indicator as to whether different clipping is applied</span>
<span class="sd">            to each layer in the model.</span>
<span class="sd">        """</span>
        <span class="k">pass</span></div>


<div class="viewcode-block" id="ConstantFlatClipper"><a class="viewcode-back" href="../../../clipping.html#opacus.utils.clipping.ConstantFlatClipper">[docs]</a><span class="k">class</span> <span class="nc">ConstantFlatClipper</span><span class="p">(</span><span class="n">NormClipper</span><span class="p">):</span>
    <span class="sd">"""</span>
<span class="sd">    A clipper that clips all gradients in such a way that their norm is</span>
<span class="sd">    at most equal to a specified value. This value is shared for all</span>
<span class="sd">    layers in a model. Note that the process of clipping really involves</span>
<span class="sd">    multiplying all gradients by a scaling factor. If this scaling factor</span>
<span class="sd">    is &gt; 1.0, it is instead capped at 1.0. The net effect is that the final</span>
<span class="sd">    norm of the scaled gradients will be less than the specified value in</span>
<span class="sd">    such a case. Thus it is better to think of the specified value as an</span>
<span class="sd">    upper bound on the norm of final clipped gradients.</span>
<span class="sd">    """</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">flat_value</span><span class="p">:</span> <span class="nb">float</span><span class="p">):</span>
        <span class="sd">"""</span>
<span class="sd">        Args:</span>
<span class="sd">            flat_value: Constant value that is used to normalize gradients</span>
<span class="sd">                such that their norm equals this value before clipping.</span>
<span class="sd">                This threshold value is used for all layers.</span>
<span class="sd">        """</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">flat_value</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="n">flat_value</span><span class="p">)</span>

<div class="viewcode-block" id="ConstantFlatClipper.calc_clipping_factors"><a class="viewcode-back" href="../../../clipping.html#opacus.utils.clipping.ConstantFlatClipper.calc_clipping_factors">[docs]</a>    <span class="k">def</span> <span class="nf">calc_clipping_factors</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">norms</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Iterator</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]:</span>
        <span class="sd">"""</span>
<span class="sd">        Calculates the clipping factor based on the given</span>
<span class="sd">        norm of gradients for all layers, so that the new</span>
<span class="sd">        norm of clipped gradients is at most equal to</span>
<span class="sd">        ``self.flat_value``.</span>

<span class="sd">        Args:</span>
<span class="sd">            norms: List containing a single tensor of dimension (1,)</span>
<span class="sd">                with the norm of all gradients.</span>

<span class="sd">        Returns:</span>
<span class="sd">            Tensor containing the single threshold value to be used</span>
<span class="sd">            for all layers.</span>
<span class="sd">        """</span>
        <span class="c1"># Expects a list of size one.</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">norms</span><span class="p">)</span> <span class="o">!=</span> <span class="mi">1</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="s2">"Waring: flat norm selected but "</span>
                <span class="sa">f</span><span class="s2">"received norm for </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">norms</span><span class="p">)</span><span class="si">}</span><span class="s2"> layers"</span>
            <span class="p">)</span>
        <span class="n">per_sample_clip_factor</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">flat_value</span> <span class="o">/</span> <span class="p">(</span><span class="n">norms</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="mf">1e-6</span><span class="p">)</span>
        <span class="c1"># We are *clipping* the gradient, so if the factor is ever &gt;1 we set it to 1</span>
        <span class="n">per_sample_clip_factor</span> <span class="o">=</span> <span class="n">per_sample_clip_factor</span><span class="o">.</span><span class="n">clamp</span><span class="p">(</span><span class="nb">max</span><span class="o">=</span><span class="mf">1.0</span><span class="p">)</span>  <span class="c1"># pyre-ignore</span>
        <span class="c1"># return this clipping factor for all layers</span>
        <span class="k">return</span> <span class="n">cycle</span><span class="p">([</span><span class="n">per_sample_clip_factor</span><span class="p">])</span></div>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">thresholds</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
        <span class="sd">"""</span>
<span class="sd">        Returns singleton tensor of dimension (1,) containing</span>
<span class="sd">        the common threshold value used for clipping all</span>
<span class="sd">        layers in the model.</span>

<span class="sd">        Returns:</span>
<span class="sd">            Threshold values</span>
<span class="sd">        """</span>
        <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="bp">self</span><span class="o">.</span><span class="n">flat_value</span><span class="p">])</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">is_per_layer</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">bool</span><span class="p">:</span>
        <span class="sd">"""</span>
<span class="sd">        Returns indicator as to whether different clipping is applied</span>
<span class="sd">        to each layer in the model. For this clipper, it is False.</span>

<span class="sd">        Returns:</span>
<span class="sd">            Flag with value False</span>
<span class="sd">        """</span>
        <span class="k">return</span> <span class="kc">False</span></div>


<div class="viewcode-block" id="ConstantPerLayerClipper"><a class="viewcode-back" href="../../../clipping.html#opacus.utils.clipping.ConstantPerLayerClipper">[docs]</a><span class="k">class</span> <span class="nc">ConstantPerLayerClipper</span><span class="p">(</span><span class="n">NormClipper</span><span class="p">):</span>
    <span class="sd">"""</span>
<span class="sd">    A clipper that clips all gradients in such a way that their norm is</span>
<span class="sd">    at most equal to a specified value. This value is specified for each</span>
<span class="sd">    layer in a model. Note that the process of clipping really involves</span>
<span class="sd">    multiplying all gradients by a scaling factor. If this scaling factor</span>
<span class="sd">    is &gt; 1.0, it is instead capped at 1.0. The net effect is that the final</span>
<span class="sd">    norm of the scaled gradients will be less than the specified value in</span>
<span class="sd">    such a case. Thus it is better to think of the specified value as an</span>
<span class="sd">    upper bound on the norm of final clipped gradients.</span>
<span class="sd">    """</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">flat_values</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">float</span><span class="p">]):</span>
        <span class="sd">"""</span>
<span class="sd">        Args:</span>
<span class="sd">            flat_values: List of values that is used to normalize gradients</span>
<span class="sd">                for each layer such that the norm equals the corresponding</span>
<span class="sd">                value before clipping.</span>
<span class="sd">        """</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">flat_values</span> <span class="o">=</span> <span class="p">[</span><span class="nb">float</span><span class="p">(</span><span class="n">fv</span><span class="p">)</span> <span class="k">for</span> <span class="n">fv</span> <span class="ow">in</span> <span class="n">flat_values</span><span class="p">]</span>

<div class="viewcode-block" id="ConstantPerLayerClipper.calc_clipping_factors"><a class="viewcode-back" href="../../../clipping.html#opacus.utils.clipping.ConstantPerLayerClipper.calc_clipping_factors">[docs]</a>    <span class="k">def</span> <span class="nf">calc_clipping_factors</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">norms</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]:</span>
        <span class="sd">"""</span>
<span class="sd">        Calculates separate clipping factors for each layer based on</span>
<span class="sd">        its corresponding norm of gradients, such that its new norm is</span>
<span class="sd">        at most equal to the flat value specified for that layer when</span>
<span class="sd">        instantiating the object of</span>
<span class="sd">        :class:`~opacus.utils.clipping.ConstantPerLayerClipper`.</span>

<span class="sd">        Args:</span>
<span class="sd">            norms: List containing the desired norm of gradients for each layer.</span>

<span class="sd">        Returns:</span>
<span class="sd">            List of tensors, each containing a single value specifying the</span>
<span class="sd">            clipping factor per layer.</span>
<span class="sd">        """</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">norms</span><span class="p">)</span> <span class="o">!=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">flat_values</span><span class="p">)</span> <span class="ow">and</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">flat_values</span><span class="p">)</span> <span class="o">!=</span> <span class="mi">1</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">"</span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">norms</span><span class="p">)</span><span class="si">}</span><span class="s2"> layers have provided norms but the "</span>
                <span class="sa">f</span><span class="s2">"number of clipping thresholds is </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">flat_values</span><span class="p">)</span><span class="si">}</span><span class="s2">"</span>
            <span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">flat_values</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">flat_values</span> <span class="o">*</span> <span class="p">(</span>
            <span class="nb">len</span><span class="p">(</span><span class="n">norms</span><span class="p">)</span> <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">flat_values</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span> <span class="k">else</span> <span class="mi">1</span>
        <span class="p">)</span>

        <span class="n">clipping_factor</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">norm</span><span class="p">,</span> <span class="n">threshold</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">norms</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">flat_values</span><span class="p">):</span>
            <span class="n">per_sample_clip_factor</span> <span class="o">=</span> <span class="n">threshold</span> <span class="o">/</span> <span class="p">(</span><span class="n">norm</span> <span class="o">+</span> <span class="mf">1e-6</span><span class="p">)</span>
            <span class="n">clipping_factor</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">per_sample_clip_factor</span><span class="o">.</span><span class="n">clamp</span><span class="p">(</span><span class="nb">max</span><span class="o">=</span><span class="mf">1.0</span><span class="p">))</span>
        <span class="k">return</span> <span class="n">clipping_factor</span></div>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">thresholds</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
        <span class="sd">"""</span>
<span class="sd">        Returns a tensor of values that are used to normalize gradients for</span>
<span class="sd">        each layer such that the norm at most equals the corresponding</span>
<span class="sd">        value before clipping.</span>

<span class="sd">        Returns:</span>
<span class="sd">            Tensor of thresholds</span>
<span class="sd">        """</span>
        <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">flat_values</span><span class="p">)</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">is_per_layer</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">bool</span><span class="p">:</span>
        <span class="sd">"""</span>
<span class="sd">        Returns indicator as to whether different clipping is applied</span>
<span class="sd">        to each layer in the model. For this clipper, it is True.</span>

<span class="sd">        Returns:</span>
<span class="sd">            Flag with value True</span>
<span class="sd">        """</span>
        <span class="k">return</span> <span class="kc">True</span></div>


<span class="k">class</span> <span class="nc">_Dynamic_Clipper_</span><span class="p">(</span><span class="n">NormClipper</span><span class="p">):</span>
    <span class="sd">"""</span>
<span class="sd">    This is a generic clipper, that is in an experimental phase.</span>
<span class="sd">    The clipper uses different stats to find a clipping threshold</span>
<span class="sd">    based on the given per sample norms.</span>

<span class="sd">    Notes:</span>
<span class="sd">        This clipper breaks DP guarantees [use only for experimentation]</span>
<span class="sd">    """</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">flat_values</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">float</span><span class="p">],</span>
        <span class="n">clip_per_layer</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="n">clipping_method</span><span class="p">:</span> <span class="n">ClippingMethod</span> <span class="o">=</span> <span class="n">ClippingMethod</span><span class="o">.</span><span class="n">STATIC</span><span class="p">,</span>
        <span class="n">ratio</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.0</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="sd">"""</span>
<span class="sd">        Args:</span>
<span class="sd">            flat_value: List of float values that is used to normalize gradients</span>
<span class="sd">                for each layer such that the norm equals the corresponding</span>
<span class="sd">                value before clipping.</span>
<span class="sd">            clip_per_layer: Flag indicating if a separate desired norm value is</span>
<span class="sd">                specified per layer or if a single value is shared for all.</span>
<span class="sd">            clipping_method: Value in the enum ClippingMethod that specifies one</span>
<span class="sd">                of the currently supported clipping types.</span>
<span class="sd">            ratio: Value that can be used to evaluate the clipping threshold</span>
<span class="sd">                for certain clipping types.</span>
<span class="sd">        """</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">flat_values</span> <span class="o">=</span> <span class="p">[</span><span class="nb">float</span><span class="p">(</span><span class="n">float_value</span><span class="p">)</span> <span class="k">for</span> <span class="n">float_value</span> <span class="ow">in</span> <span class="n">flat_values</span><span class="p">]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">clip_per_layer</span> <span class="o">=</span> <span class="n">clip_per_layer</span>
        <span class="k">if</span> <span class="n">clipping_method</span> <span class="o">!=</span> <span class="n">ClippingMethod</span><span class="o">.</span><span class="n">STATIC</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span>
                <span class="s2">"Warning! Current implementations of dynamic clipping "</span>
                <span class="s2">"are not privacy safe; Caclulated privacy loss is not "</span>
                <span class="s2">"indicative of a proper bound."</span>
            <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">clipping_method</span> <span class="o">=</span> <span class="n">clipping_method</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">ratio</span> <span class="o">=</span> <span class="n">ratio</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">thresh</span> <span class="o">=</span> <span class="p">[]</span>

    <span class="k">def</span> <span class="nf">calc_clipping_factors</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">norms</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Union</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">],</span> <span class="n">Iterator</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]]:</span>
        <span class="sd">"""</span>
<span class="sd">        Calculates separate clipping factors for each layer based on</span>
<span class="sd">        stats such as a threshold determined by Otsu's method, combinations</span>
<span class="sd">        of mean and std. deviation, kth median value etc.</span>

<span class="sd">        This is experimental and does not guarantee privacy and is not recommended</span>
<span class="sd">        for production use.</span>

<span class="sd">        Args:</span>
<span class="sd">            norms: List containing the desired norm of gradients for each layer.</span>

<span class="sd">        Returns:</span>
<span class="sd">            Singleton list specifying a common clippng factor for all layers,</span>
<span class="sd">            or an iterator of tensors specifying a clipping factor per layer</span>
<span class="sd">        """</span>

        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">thresh</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">current_threshs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">flat_values</span>
            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">flat_values</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">clip_per_layer</span><span class="p">:</span>
                <span class="c1"># a constant clipping factor applied to all non-rozen layers</span>
                <span class="c1"># need to replicate it by the number of number of those layers</span>
                <span class="c1"># (= number of norms).</span>
                <span class="n">current_threshs</span> <span class="o">*=</span> <span class="nb">len</span><span class="p">(</span><span class="n">norms</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">current_threshs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">thresh</span>

        <span class="n">clipping_factor</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">thresh</span> <span class="o">=</span> <span class="p">[]</span>

        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">norms</span><span class="p">)</span> <span class="o">!=</span> <span class="nb">len</span><span class="p">(</span><span class="n">current_threshs</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">"Provided grad norm max's size </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">current_threshs</span><span class="p">)</span><span class="si">}</span><span class="s2">"</span>
                <span class="sa">f</span><span class="s2">" does not match the number of layers </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">norms</span><span class="p">)</span><span class="si">}</span><span class="s2">"</span>
            <span class="p">)</span>

        <span class="k">for</span> <span class="n">norm</span><span class="p">,</span> <span class="n">current_thresh</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">norms</span><span class="p">,</span> <span class="n">current_threshs</span><span class="p">):</span>
            <span class="n">thresh</span> <span class="o">=</span> <span class="n">_calculate_thresh_value</span><span class="p">(</span>
                <span class="n">norm</span><span class="p">,</span> <span class="n">current_thresh</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">clipping_method</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">ratio</span>
            <span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">thresh</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">thresh</span><span class="p">)</span>
            <span class="n">per_sample_clip_factor</span> <span class="o">=</span> <span class="n">thresh</span> <span class="o">/</span> <span class="p">(</span><span class="n">norm</span> <span class="o">+</span> <span class="mf">1e-6</span><span class="p">)</span>
            <span class="n">clipping_factor</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">per_sample_clip_factor</span><span class="o">.</span><span class="n">clamp</span><span class="p">(</span><span class="nb">max</span><span class="o">=</span><span class="mf">1.0</span><span class="p">))</span>  <span class="c1"># pyre-ignore</span>
        <span class="k">return</span> <span class="n">clipping_factor</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">is_per_layer</span> <span class="k">else</span> <span class="n">cycle</span><span class="p">(</span><span class="n">clipping_factor</span><span class="p">)</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">thresholds</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
        <span class="sd">"""</span>
<span class="sd">        Returns a tensor of values that are used to normalize gradients</span>
<span class="sd">        for each layer such that the norm at most equals the corresponding</span>
<span class="sd">        value before clipping.</span>

<span class="sd">        Returns:</span>
<span class="sd">            Tensor of thresholds</span>
<span class="sd">        """</span>
        <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">thresh</span><span class="p">)</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">is_per_layer</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">bool</span><span class="p">:</span>
        <span class="sd">"""</span>
<span class="sd">        Returns indicator as to whether different clipping is applied</span>
<span class="sd">        to each layer in the model.</span>

<span class="sd">        Returns:</span>
<span class="sd">            Value of the flag</span>
<span class="sd">        """</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">clip_per_layer</span>
</pre></div>
</div>
</div>
</div>
<div aria-label="main navigation" class="sphinxsidebar" role="navigation">
<div class="sphinxsidebarwrapper">
<h1 class="logo"><a href="../../../index.html">Opacus</a></h1>
<h3>Navigation</h3>
<p class="caption"><span class="caption-text">API Reference</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../privacy_engine.html">Privacy Engine</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../privacy_analysis.html">Privacy Analysis</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../per_sample_gradient_clip.html">Gradient Clipping</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../per_sample_gradients.html">Per Sample Gradients</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../layers.html">DP Layers</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../utils.html">Utils</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../scripts.html">Scripts</a></li>
</ul>
<div class="relations">
<h3>Related Topics</h3>
<ul>
<li><a href="../../../index.html">Documentation overview</a><ul>
<li><a href="../../index.html">Module code</a><ul>
</ul></li>
</ul></li>
</ul>
</div>
<div id="searchbox" role="search" style="display: none">
<h3 id="searchlabel">Quick search</h3>
<div class="searchformwrapper">
<form action="../../../search.html" class="search" method="get">
<input aria-labelledby="searchlabel" name="q" type="text"/>
<input type="submit" value="Go"/>
</form>
</div>
</div>
<script>$('#searchbox').show(0);</script>
</div>
</div>
<div class="clearer"></div>
</div></div></div><footer class="nav-footer" id="footer"><section class="sitemap"><a href="/" class="nav-home"><img src="/img/opacus_favicon.svg" alt="Opacus" width="66" height="58"/></a><div class="footerSection"><h5>Docs</h5><a href="/docs/introduction">Introduction</a><a href="/docs/faq">FAQ</a><a href="/tutorials/">Tutorials</a><a href="/api/">API Reference</a></div><div class="footerSection"><h5>Social</h5><div class="social"><a class="github-button" href="https://github.com/pytorch/opacus" data-count-href="https://github.com/pytorch/opacus/stargazers" data-show-count="true" data-count-aria-label="# stargazers on GitHub" aria-label="Star Opacus on GitHub">opacus</a></div></div></section><a href="https://opensource.facebook.com/" target="_blank" rel="noreferrer noopener" class="fbOpenSource"><img src="/img/oss_logo.png" alt="Facebook Open Source" width="170" height="45"/></a><section class="copyright"> Copyright © 2020 Facebook Inc.</section></footer></div><script type="text/javascript" src="https://cdn.jsdelivr.net/docsearch.js/1/docsearch.min.js"></script><script>
                document.addEventListener('keyup', function(e) {
                  if (e.target !== document.body) {
                    return;
                  }
                  // keyCode for '/' (slash)
                  if (e.keyCode === 191) {
                    const search = document.getElementById('search_input_react');
                    search && search.focus();
                  }
                });
              </script><script>
              var search = docsearch({
                
                apiKey: '207c27d819f967749142d8611de7cb19',
                indexName: 'opacus',
                inputSelector: '#search_input_react'
              });
            </script></body></html>