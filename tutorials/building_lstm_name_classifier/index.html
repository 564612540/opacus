<!DOCTYPE html><html lang=""><head><meta charSet="utf-8"/><meta http-equiv="X-UA-Compatible" content="IE=edge"/><title>Opacus · Train PyTorch models with Differential Privacy</title><meta name="viewport" content="width=device-width, initial-scale=1.0"/><meta name="generator" content="Docusaurus"/><meta name="description" content="Train PyTorch models with Differential Privacy"/><meta property="og:title" content="Opacus · Train PyTorch models with Differential Privacy"/><meta property="og:type" content="website"/><meta property="og:url" content="https://opacus.ai/"/><meta property="og:description" content="Train PyTorch models with Differential Privacy"/><meta property="og:image" content="https://opacus.ai/img/opacus_logo.svg"/><meta name="twitter:card" content="summary"/><meta name="twitter:image" content="https://opacus.ai/img/opacus_logo.svg"/><link rel="shortcut icon" href="/img/opacus_favicon.svg"/><link rel="stylesheet" href="https://cdn.jsdelivr.net/docsearch.js/1/docsearch.min.css"/><link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/default.min.css"/><script>
              (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
              (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
              m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
              })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

              ga('create', 'UA-117752657-3', 'auto');
              ga('send', 'pageview');
            </script><link rel="stylesheet" href="/css/code_block_buttons.css"/><script type="text/javascript" src="https://buttons.github.io/buttons.js"></script><script type="text/javascript" src="/js/code_block_buttons.js"></script><script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.0/clipboard.min.js"></script><script type="text/javascript" src="/js/mathjax.js"></script><script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-AMS_HTML"></script><script src="https://unpkg.com/vanilla-back-to-top@7.1.14/dist/vanilla-back-to-top.min.js"></script><script>
        document.addEventListener('DOMContentLoaded', function() {
          addBackToTop(
            {"zIndex":100}
          )
        });
        </script><script src="/js/scrollSpy.js"></script><link rel="stylesheet" href="/css/main.css"/><script src="/js/codetabs.js"></script></head><body><div class="fixedHeaderContainer"><div class="headerWrapper wrapper"><header><a href="/"><img class="logo" src="/img/opacus_logo.svg" alt="Opacus"/></a><div class="navigationWrapper navigationSlider"><nav class="slidingNav"><ul class="nav-site nav-site-internal"><li class=""><a href="/docs/introduction" target="_self">Introduction</a></li><li class=""><a href="/docs/faq" target="_self">FAQ</a></li><li class=""><a href="/tutorials/" target="_self">Tutorials</a></li><li class=""><a href="/api/" target="_self">API Reference</a></li><li class=""><a href="https://github.com/pytorch/opacus" target="_self">GitHub</a></li><li class="navSearchWrapper reactNavSearchWrapper"><input type="text" id="search_input_react" placeholder="Search" title="Search"/></li></ul></nav></div></header></div></div><div class="navPusher"><div class="docMainWrapper wrapper"><div class="container docsNavContainer" id="docsNav"><nav class="toc"><div class="toggleNav"><section class="navWrapper wrapper"><div class="navBreadcrumb wrapper"><div class="navToggle" id="navToggler"><div class="hamburger-menu"><div class="line1"></div><div class="line2"></div><div class="line3"></div></div></div><h2><i>›</i><span></span></h2><div class="tocToggler" id="tocToggler"><i class="icon-toc"></i></div></div><div class="navGroups"><div class="navGroup"><h3 class="navGroupCategoryTitle">Tutorials</h3><ul class=""><li class="navListItem"><a class="navItem" href="/tutorials/">Overview</a></li></ul></div><div class="navGroup"><h3 class="navGroupCategoryTitle">Using Opacus</h3><ul class=""><li class="navListItem"><a class="navItem" href="/tutorials/building_image_classifier">Building image classifier with Differential Privacy</a></li><li class="navListItem"><a class="navItem" href="/tutorials/building_text_classifier">Building text classifier with Differential Privacy</a></li><li class="navListItem navListItemActive"><a class="navItem" href="/tutorials/building_lstm_name_classifier">Training a differentially private LSTM model for name classification</a></li></ul></div></div></section></div><script>
            var coll = document.getElementsByClassName('collapsible');
            var checkActiveCategory = true;
            for (var i = 0; i < coll.length; i++) {
              var links = coll[i].nextElementSibling.getElementsByTagName('*');
              if (checkActiveCategory){
                for (var j = 0; j < links.length; j++) {
                  if (links[j].classList.contains('navListItemActive')){
                    coll[i].nextElementSibling.classList.toggle('hide');
                    coll[i].childNodes[1].classList.toggle('rotate');
                    checkActiveCategory = false;
                    break;
                  }
                }
              }

              coll[i].addEventListener('click', function() {
                var arrow = this.childNodes[1];
                arrow.classList.toggle('rotate');
                var content = this.nextElementSibling;
                content.classList.toggle('hide');
              });
            }

            document.addEventListener('DOMContentLoaded', function() {
              createToggler('#navToggler', '#docsNav', 'docsSliderActive');
              createToggler('#tocToggler', 'body', 'tocActive');

              var headings = document.querySelector('.toc-headings');
              headings && headings.addEventListener('click', function(event) {
                var el = event.target;
                while(el !== headings){
                  if (el.tagName === 'A') {
                    document.body.classList.remove('tocActive');
                    break;
                  } else{
                    el = el.parentNode;
                  }
                }
              }, false);

              function createToggler(togglerSelector, targetSelector, className) {
                var toggler = document.querySelector(togglerSelector);
                var target = document.querySelector(targetSelector);

                if (!toggler) {
                  return;
                }

                toggler.onclick = function(event) {
                  event.preventDefault();

                  target.classList.toggle(className);
                };
              }
            });
        </script></nav></div><div class="container mainContainer"><div class="wrapper"><div class="tutorialBody">
<script
  src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.1.10/require.min.js">
</script>
<script
  src="https://cdnjs.cloudflare.com/ajax/libs/jquery/2.0.3/jquery.min.js">
</script>
<div class="notebook">
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Training-a-differentially-private-LSTM-model-for-name-classification">Training a differentially private LSTM model for name classification<a class="anchor-link" href="#Training-a-differentially-private-LSTM-model-for-name-classification">¶</a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>In this tutorial we will build a differentially-private LSTM model to classify names to their source languages, which is the same task as in the tutorial <strong>NLP From Scratch</strong> (<a href="https://pytorch.org/tutorials/intermediate/char_rnn_classification_tutorial.html">https://pytorch.org/tutorials/intermediate/char_rnn_classification_tutorial.html</a>). Since the objective of this tutorial is to demonstrate the effective use of an LSTM with privacy guarantees, we will be utilizing it in place of the bare-bones RNN model defined in the original tutorial. Specifically, we use the <code>DPLSTM</code> module from <code>opacus.layers.dp_lstm</code> to facilitate calculation of the per-example gradients, which are utilized in the addition of noise during application of differential privacy. <code>DPLSTM</code> has the same API and functionality as the <code>nn.LSTM</code>, with some restrictions (ex. we currently support single layers, the full list is given below).</p>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Dataset">Dataset<a class="anchor-link" href="#Dataset">¶</a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>First, let us download the dataset of names and their associated language labels as given in <a href="https://pytorch.org/tutorials/intermediate/char_rnn_classification_tutorial.html">https://pytorch.org/tutorials/intermediate/char_rnn_classification_tutorial.html</a>. We train our differentially-private LSTM on the same dataset as in that tutorial.</p>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In [1]:</div>
<div class="inner_cell">
<div class="input_area">
<div class="highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">requests</span>

<span class="n">NAMES_DATASET_URL</span> <span class="o">=</span> <span class="s2">"https://download.pytorch.org/tutorial/data.zip"</span>
<span class="n">DATA_DIR</span> <span class="o">=</span> <span class="s2">"names"</span>

<span class="kn">import</span> <span class="nn">zipfile</span>
<span class="kn">import</span> <span class="nn">urllib</span>

<span class="k">def</span> <span class="nf">download_and_extract</span><span class="p">(</span><span class="n">dataset_url</span><span class="p">,</span> <span class="n">data_dir</span><span class="p">):</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">"Downloading and extracting ..."</span><span class="p">)</span>
    <span class="n">filename</span> <span class="o">=</span> <span class="s2">"data.zip"</span>

    <span class="n">urllib</span><span class="o">.</span><span class="n">request</span><span class="o">.</span><span class="n">urlretrieve</span><span class="p">(</span><span class="n">dataset_url</span><span class="p">,</span> <span class="n">filename</span><span class="p">)</span>
    <span class="k">with</span> <span class="n">zipfile</span><span class="o">.</span><span class="n">ZipFile</span><span class="p">(</span><span class="n">filename</span><span class="p">)</span> <span class="k">as</span> <span class="n">zip_ref</span><span class="p">:</span>
        <span class="n">zip_ref</span><span class="o">.</span><span class="n">extractall</span><span class="p">(</span><span class="n">data_dir</span><span class="p">)</span>
    <span class="n">os</span><span class="o">.</span><span class="n">remove</span><span class="p">(</span><span class="n">filename</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">"Completed!"</span><span class="p">)</span>

<span class="n">download_and_extract</span><span class="p">(</span><span class="n">NAMES_DATASET_URL</span><span class="p">,</span> <span class="n">DATA_DIR</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="output_wrapper">
<div class="output">
<div class="output_area">
<div class="prompt"></div>
<div class="output_subarea output_stream output_stdout output_text">
<pre>Downloading and extracting ...
Completed!
</pre>
</div>
</div>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In [2]:</div>
<div class="inner_cell">
<div class="input_area">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">names_folder</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">DATA_DIR</span><span class="p">,</span> <span class="s1">'data'</span><span class="p">,</span> <span class="s1">'names'</span><span class="p">)</span>
<span class="n">all_filenames</span> <span class="o">=</span> <span class="p">[]</span>

<span class="k">for</span> <span class="n">language_file</span> <span class="ow">in</span> <span class="n">os</span><span class="o">.</span><span class="n">listdir</span><span class="p">(</span><span class="n">names_folder</span><span class="p">):</span>
    <span class="n">all_filenames</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">names_folder</span><span class="p">,</span> <span class="n">language_file</span><span class="p">))</span>
    
<span class="nb">print</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">listdir</span><span class="p">(</span><span class="n">names_folder</span><span class="p">))</span>
</pre></div>
</div>
</div>
</div>
<div class="output_wrapper">
<div class="output">
<div class="output_area">
<div class="prompt"></div>
<div class="output_subarea output_stream output_stdout output_text">
<pre>['Arabic.txt', 'Chinese.txt', 'Czech.txt', 'Dutch.txt', 'English.txt', 'French.txt', 'German.txt', 'Greek.txt', 'Irish.txt', 'Italian.txt', 'Japanese.txt', 'Korean.txt', 'Polish.txt', 'Portuguese.txt', 'Russian.txt', 'Scottish.txt', 'Spanish.txt', 'Vietnamese.txt']
</pre>
</div>
</div>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In [3]:</div>
<div class="inner_cell">
<div class="input_area">
<div class="highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">torch.nn</span> <span class="k">as</span> <span class="nn">nn</span>

<span class="k">class</span> <span class="nc">CharByteEncoder</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="sd">"""</span>
<span class="sd">    This encoder takes a UTF-8 string and encodes its bytes into a Tensor. It can also</span>
<span class="sd">    perform the opposite operation to check a result.</span>
<span class="sd">    Examples:</span>
<span class="sd">    &gt;&gt;&gt; encoder = CharByteEncoder()</span>
<span class="sd">    &gt;&gt;&gt; t = encoder('Ślusàrski')  # returns tensor([256, 197, 154, 108, 117, 115, 195, 160, 114, 115, 107, 105, 257])</span>
<span class="sd">    &gt;&gt;&gt; encoder.decode(t)  # returns "&lt;s&gt;Ślusàrski&lt;/s&gt;"</span>
<span class="sd">    """</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">start_token</span> <span class="o">=</span> <span class="s2">"&lt;s&gt;"</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">end_token</span> <span class="o">=</span> <span class="s2">"&lt;/s&gt;"</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">pad_token</span> <span class="o">=</span> <span class="s2">"&lt;pad&gt;"</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">start_idx</span> <span class="o">=</span> <span class="mi">256</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">end_idx</span> <span class="o">=</span> <span class="mi">257</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">pad_idx</span> <span class="o">=</span> <span class="mi">258</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">s</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">pad_to</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">LongTensor</span><span class="p">:</span>
        <span class="sd">"""</span>
<span class="sd">        Encodes a string. It will append a start token &lt;s&gt; (id=self.start_idx) and an end token &lt;/s&gt;</span>
<span class="sd">        (id=self.end_idx).</span>
<span class="sd">        Args:</span>
<span class="sd">            s: The string to encode.</span>
<span class="sd">            pad_to: If not zero, pad by appending self.pad_idx until string is of length `pad_to`.</span>
<span class="sd">                Defaults to 0.</span>
<span class="sd">        Returns:</span>
<span class="sd">            The encoded LongTensor of indices.</span>
<span class="sd">        """</span>
        <span class="n">encoded</span> <span class="o">=</span> <span class="n">s</span><span class="o">.</span><span class="n">encode</span><span class="p">()</span>
        <span class="n">n_pad</span> <span class="o">=</span> <span class="n">pad_to</span> <span class="o">-</span> <span class="nb">len</span><span class="p">(</span><span class="n">encoded</span><span class="p">)</span> <span class="k">if</span> <span class="n">pad_to</span> <span class="o">&gt;</span> <span class="nb">len</span><span class="p">(</span><span class="n">encoded</span><span class="p">)</span> <span class="k">else</span> <span class="mi">0</span>
        <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">LongTensor</span><span class="p">(</span>
            <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">start_idx</span><span class="p">]</span>
            <span class="o">+</span> <span class="p">[</span><span class="n">c</span> <span class="k">for</span> <span class="n">c</span> <span class="ow">in</span> <span class="n">encoded</span><span class="p">]</span>  <span class="c1"># noqa</span>
            <span class="o">+</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">end_idx</span><span class="p">]</span>
            <span class="o">+</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">pad_idx</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_pad</span><span class="p">)]</span>
        <span class="p">)</span>

    <span class="k">def</span> <span class="nf">decode</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">char_ids_tensor</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">LongTensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
        <span class="sd">"""</span>
<span class="sd">        The inverse of `forward`. Keeps the start, end and pad indices.</span>
<span class="sd">        """</span>
        <span class="n">char_ids</span> <span class="o">=</span> <span class="n">char_ids_tensor</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span>

        <span class="n">out</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">buf</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">c</span> <span class="ow">in</span> <span class="n">char_ids</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">c</span> <span class="o">&lt;</span> <span class="mi">256</span><span class="p">:</span>
                <span class="n">buf</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">c</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">if</span> <span class="n">buf</span><span class="p">:</span>
                    <span class="n">out</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="nb">bytes</span><span class="p">(</span><span class="n">buf</span><span class="p">)</span><span class="o">.</span><span class="n">decode</span><span class="p">())</span>
                    <span class="n">buf</span> <span class="o">=</span> <span class="p">[]</span>
                <span class="k">if</span> <span class="n">c</span> <span class="o">==</span> <span class="bp">self</span><span class="o">.</span><span class="n">start_idx</span><span class="p">:</span>
                    <span class="n">out</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">start_token</span><span class="p">)</span>
                <span class="k">elif</span> <span class="n">c</span> <span class="o">==</span> <span class="bp">self</span><span class="o">.</span><span class="n">end_idx</span><span class="p">:</span>
                    <span class="n">out</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">end_token</span><span class="p">)</span>
                <span class="k">elif</span> <span class="n">c</span> <span class="o">==</span> <span class="bp">self</span><span class="o">.</span><span class="n">pad_idx</span><span class="p">:</span>
                    <span class="n">out</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">pad_token</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">buf</span><span class="p">:</span>  <span class="c1"># in case some are left</span>
            <span class="n">out</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="nb">bytes</span><span class="p">(</span><span class="n">buf</span><span class="p">)</span><span class="o">.</span><span class="n">decode</span><span class="p">())</span>
        <span class="k">return</span> <span class="s2">""</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>

    <span class="k">def</span> <span class="fm">__len__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">"""</span>
<span class="sd">        The length of our encoder space. This is fixed to 256 (one byte) + 3 special chars</span>
<span class="sd">        (start, end, pad).</span>
<span class="sd">        Returns:</span>
<span class="sd">            259</span>
<span class="sd">        """</span>
        <span class="k">return</span> <span class="mi">259</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Training-/-Validation-Set-Preparation">Training / Validation Set Preparation<a class="anchor-link" href="#Training-/-Validation-Set-Preparation">¶</a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In [4]:</div>
<div class="inner_cell">
<div class="input_area">
<div class="highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">torch.nn.utils.rnn</span> <span class="kn">import</span> <span class="n">pad_sequence</span>

<span class="k">def</span> <span class="nf">padded_collate</span><span class="p">(</span><span class="n">batch</span><span class="p">,</span> <span class="n">padding_idx</span><span class="o">=</span><span class="mi">0</span><span class="p">):</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">pad_sequence</span><span class="p">(</span>
        <span class="p">[</span><span class="n">elem</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="k">for</span> <span class="n">elem</span> <span class="ow">in</span> <span class="n">batch</span><span class="p">],</span> <span class="n">batch_first</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">padding_value</span><span class="o">=</span><span class="n">padding_idx</span>
    <span class="p">)</span>
    <span class="n">y</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">([</span><span class="n">elem</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="k">for</span> <span class="n">elem</span> <span class="ow">in</span> <span class="n">batch</span><span class="p">])</span><span class="o">.</span><span class="n">long</span><span class="p">()</span>

    <span class="k">return</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In [5]:</div>
<div class="inner_cell">
<div class="input_area">
<div class="highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">torch.utils.data</span> <span class="kn">import</span> <span class="n">Dataset</span>
<span class="kn">from</span> <span class="nn">pathlib</span> <span class="kn">import</span> <span class="n">Path</span>


<span class="k">class</span> <span class="nc">NamesDataset</span><span class="p">(</span><span class="n">Dataset</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">root</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">root</span> <span class="o">=</span> <span class="n">Path</span><span class="p">(</span><span class="n">root</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">labels</span> <span class="o">=</span> <span class="nb">list</span><span class="p">({</span><span class="n">langfile</span><span class="o">.</span><span class="n">stem</span> <span class="k">for</span> <span class="n">langfile</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">root</span><span class="o">.</span><span class="n">iterdir</span><span class="p">()})</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">labels_dict</span> <span class="o">=</span> <span class="p">{</span><span class="n">label</span><span class="p">:</span> <span class="n">i</span> <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">label</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">labels</span><span class="p">)}</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">encoder</span> <span class="o">=</span> <span class="n">CharByteEncoder</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">samples</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">construct_samples</span><span class="p">()</span>

    <span class="k">def</span> <span class="fm">__getitem__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">i</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">samples</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>

    <span class="k">def</span> <span class="fm">__len__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">samples</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">construct_samples</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="n">samples</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">langfile</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">root</span><span class="o">.</span><span class="n">iterdir</span><span class="p">():</span>
            <span class="n">label_name</span> <span class="o">=</span> <span class="n">langfile</span><span class="o">.</span><span class="n">stem</span>
            <span class="n">label_id</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">labels_dict</span><span class="p">[</span><span class="n">label_name</span><span class="p">]</span>
            <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">langfile</span><span class="p">,</span> <span class="s2">"r"</span><span class="p">)</span> <span class="k">as</span> <span class="n">fin</span><span class="p">:</span>
                <span class="k">for</span> <span class="n">row</span> <span class="ow">in</span> <span class="n">fin</span><span class="p">:</span>
                    <span class="n">samples</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
                        <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">encoder</span><span class="p">(</span><span class="n">row</span><span class="o">.</span><span class="n">strip</span><span class="p">()),</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">label_id</span><span class="p">)</span><span class="o">.</span><span class="n">long</span><span class="p">())</span>
                    <span class="p">)</span>
        <span class="k">return</span> <span class="n">samples</span>

    <span class="k">def</span> <span class="nf">label_count</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="n">cnt</span> <span class="o">=</span> <span class="n">Counter</span><span class="p">()</span>
        <span class="k">for</span> <span class="n">_x</span><span class="p">,</span> <span class="n">y</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">samples</span><span class="p">:</span>
            <span class="n">label</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">labels</span><span class="p">[</span><span class="nb">int</span><span class="p">(</span><span class="n">y</span><span class="p">)]</span>
            <span class="n">cnt</span><span class="p">[</span><span class="n">label</span><span class="p">]</span> <span class="o">+=</span> <span class="mi">1</span>
        <span class="k">return</span> <span class="n">cnt</span>


<span class="n">VOCAB_SIZE</span> <span class="o">=</span> <span class="mi">256</span> <span class="o">+</span> <span class="mi">3</span>  <span class="c1"># 256 alternatives in one byte, plus 3 special characters.</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>We split the dataset into a 80-20 split for training and validation.</p>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In [6]:</div>
<div class="inner_cell">
<div class="input_area">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">secure_rng</span> <span class="o">=</span> <span class="kc">False</span>
<span class="n">train_split</span> <span class="o">=</span> <span class="mf">0.8</span>
<span class="n">test_every</span> <span class="o">=</span> <span class="mi">5</span>
<span class="n">batch_size</span> <span class="o">=</span> <span class="mi">800</span>

<span class="n">ds</span> <span class="o">=</span> <span class="n">NamesDataset</span><span class="p">(</span><span class="n">names_folder</span><span class="p">)</span>
<span class="n">train_len</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">train_split</span> <span class="o">*</span> <span class="nb">len</span><span class="p">(</span><span class="n">ds</span><span class="p">))</span>
<span class="n">test_len</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">ds</span><span class="p">)</span> <span class="o">-</span> <span class="n">train_len</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"</span><span class="si">{</span><span class="n">train_len</span><span class="si">}</span><span class="s2"> samples for training, </span><span class="si">{</span><span class="n">test_len</span><span class="si">}</span><span class="s2"> for testing"</span><span class="p">)</span>

<span class="k">if</span> <span class="n">secure_rng</span><span class="p">:</span>
    <span class="k">try</span><span class="p">:</span>
        <span class="kn">import</span> <span class="nn">torchcsprng</span> <span class="k">as</span> <span class="nn">prng</span>
    <span class="k">except</span> <span class="ne">ImportError</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
        <span class="n">msg</span> <span class="o">=</span> <span class="p">(</span>
            <span class="s2">"To use secure RNG, you must install the torchcsprng package! "</span>
            <span class="s2">"Check out the instructions here: https://github.com/pytorch/csprng#installation"</span>
        <span class="p">)</span>
        <span class="k">raise</span> <span class="ne">ImportError</span><span class="p">(</span><span class="n">msg</span><span class="p">)</span> <span class="kn">from</span> <span class="nn">e</span>

    <span class="n">generator</span> <span class="o">=</span> <span class="n">prng</span><span class="o">.</span><span class="n">create_random_device_generator</span><span class="p">(</span><span class="s2">"/dev/urandom"</span><span class="p">)</span>

<span class="k">else</span><span class="p">:</span>
    <span class="n">generator</span> <span class="o">=</span> <span class="kc">None</span>

<span class="n">train_ds</span><span class="p">,</span> <span class="n">test_ds</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">random_split</span><span class="p">(</span>
    <span class="n">ds</span><span class="p">,</span> <span class="p">[</span><span class="n">train_len</span><span class="p">,</span> <span class="n">test_len</span><span class="p">],</span> <span class="n">generator</span><span class="o">=</span><span class="n">generator</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="output_wrapper">
<div class="output">
<div class="output_area">
<div class="prompt"></div>
<div class="output_subarea output_stream output_stdout output_text">
<pre>16059 samples for training, 4015 for testing
</pre>
</div>
</div>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In [7]:</div>
<div class="inner_cell">
<div class="input_area">
<div class="highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">torch.utils.data</span> <span class="kn">import</span> <span class="n">DataLoader</span>
<span class="kn">from</span> <span class="nn">opacus.utils.uniform_sampler</span> <span class="kn">import</span> <span class="n">UniformWithReplacementSampler</span>

<span class="n">sample_rate</span> <span class="o">=</span> <span class="n">batch_size</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">train_ds</span><span class="p">)</span>

<span class="n">train_loader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span>
    <span class="n">train_ds</span><span class="p">,</span>
    <span class="n">num_workers</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span>
    <span class="n">pin_memory</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="n">generator</span><span class="o">=</span><span class="n">generator</span><span class="p">,</span>
    <span class="n">batch_sampler</span><span class="o">=</span><span class="n">UniformWithReplacementSampler</span><span class="p">(</span>
        <span class="n">num_samples</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="n">train_ds</span><span class="p">),</span>
        <span class="n">sample_rate</span><span class="o">=</span><span class="n">sample_rate</span><span class="p">,</span>
        <span class="n">generator</span><span class="o">=</span><span class="n">generator</span><span class="p">,</span>
    <span class="p">),</span>
    <span class="n">collate_fn</span><span class="o">=</span><span class="n">padded_collate</span><span class="p">,</span>
<span class="p">)</span>

<span class="n">test_loader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span>
    <span class="n">test_ds</span><span class="p">,</span>
    <span class="n">batch_size</span><span class="o">=</span><span class="mi">2</span> <span class="o">*</span> <span class="n">batch_size</span><span class="p">,</span>
    <span class="n">shuffle</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
    <span class="n">num_workers</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span>
    <span class="n">pin_memory</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="n">collate_fn</span><span class="o">=</span><span class="n">padded_collate</span><span class="p">,</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>After splitting the dataset into a training and a validation set, we now have to convert the data into a numeric form suitable for training the LSTM model. For each name, we set a maximum sequence length of 15, and if a name is longer than the threshold, we truncate it (this rarely happens this dataset !). If a name is smaller than the threshold, we add a dummy <code>#</code> character to pad it to the desired length. We also batch the names in the dataset and set a batch size of 256 for all the experiments in this tutorial. The function <code>line_to_tensor()</code> returns a tensor of shape [15, 256] where each element is the index (in <code>all_letters</code>) of the corresponding character.</p>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Training/Evaluation-Cycle">Training/Evaluation Cycle<a class="anchor-link" href="#Training/Evaluation-Cycle">¶</a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>The training and the evaluation functions <code>train()</code> and <code>test()</code> are defined below. During the training loop, the per-example gradients are computed and the parameters are updated subsequent to gradient clipping (to bound their sensitivity) and addition of noise.</p>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In [8]:</div>
<div class="inner_cell">
<div class="input_area">
<div class="highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">statistics</span> <span class="kn">import</span> <span class="n">mean</span>

<span class="k">def</span> <span class="nf">train</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">criterion</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">train_loader</span><span class="p">,</span> <span class="n">epoch</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="s2">"cuda:0"</span><span class="p">):</span>
    <span class="n">accs</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">losses</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="ow">in</span> <span class="n">tqdm</span><span class="p">(</span><span class="n">train_loader</span><span class="p">):</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
        <span class="n">y</span> <span class="o">=</span> <span class="n">y</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>

        <span class="n">logits</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="n">criterion</span><span class="p">(</span><span class="n">logits</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
        <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>

        <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
        <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>

        <span class="n">preds</span> <span class="o">=</span> <span class="n">logits</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">n_correct</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="n">preds</span><span class="o">.</span><span class="n">eq</span><span class="p">(</span><span class="n">y</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">())</span>
        <span class="n">batch_accuracy</span> <span class="o">=</span> <span class="n">n_correct</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>

        <span class="n">accs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">batch_accuracy</span><span class="p">)</span>
        <span class="n">losses</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="nb">float</span><span class="p">(</span><span class="n">loss</span><span class="p">))</span>

    <span class="n">printstr</span> <span class="o">=</span> <span class="p">(</span>
        <span class="sa">f</span><span class="s2">"</span><span class="se">\t</span><span class="s2"> Epoch </span><span class="si">{</span><span class="n">epoch</span><span class="si">}</span><span class="s2">. Accuracy: </span><span class="si">{</span><span class="n">mean</span><span class="p">(</span><span class="n">accs</span><span class="p">)</span><span class="si">:</span><span class="s2">.6f</span><span class="si">}</span><span class="s2"> | Loss: </span><span class="si">{</span><span class="n">mean</span><span class="p">(</span><span class="n">losses</span><span class="p">)</span><span class="si">:</span><span class="s2">.6f</span><span class="si">}</span><span class="s2">"</span>
    <span class="p">)</span>
    <span class="k">try</span><span class="p">:</span>
        <span class="n">privacy_engine</span> <span class="o">=</span> <span class="n">optimizer</span><span class="o">.</span><span class="n">privacy_engine</span>
        <span class="n">epsilon</span><span class="p">,</span> <span class="n">best_alpha</span> <span class="o">=</span> <span class="n">privacy_engine</span><span class="o">.</span><span class="n">get_privacy_spent</span><span class="p">()</span>
        <span class="n">printstr</span> <span class="o">+=</span> <span class="sa">f</span><span class="s2">" | (ε = </span><span class="si">{</span><span class="n">epsilon</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">, δ = </span><span class="si">{</span><span class="n">privacy_engine</span><span class="o">.</span><span class="n">target_delta</span><span class="si">}</span><span class="s2">) for α = </span><span class="si">{</span><span class="n">best_alpha</span><span class="si">}</span><span class="s2">"</span>
    <span class="k">except</span> <span class="ne">AttributeError</span><span class="p">:</span>
        <span class="k">pass</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">printstr</span><span class="p">)</span>
    <span class="k">return</span>


<span class="k">def</span> <span class="nf">test</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">test_loader</span><span class="p">,</span> <span class="n">privacy_engine</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="s2">"cuda:0"</span><span class="p">):</span>
    <span class="n">accs</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
        <span class="k">for</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="ow">in</span> <span class="n">tqdm</span><span class="p">(</span><span class="n">test_loader</span><span class="p">):</span>
            <span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
            <span class="n">y</span> <span class="o">=</span> <span class="n">y</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>

            <span class="n">preds</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">x</span><span class="p">)</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
            <span class="n">n_correct</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="n">preds</span><span class="o">.</span><span class="n">eq</span><span class="p">(</span><span class="n">y</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">())</span>
            <span class="n">batch_accuracy</span> <span class="o">=</span> <span class="n">n_correct</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>

            <span class="n">accs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">batch_accuracy</span><span class="p">)</span>
    <span class="n">printstr</span> <span class="o">=</span> <span class="s2">"</span><span class="se">\n</span><span class="s2">----------------------------</span><span class="se">\n</span><span class="s2">"</span> <span class="sa">f</span><span class="s2">"Test Accuracy: </span><span class="si">{</span><span class="n">mean</span><span class="p">(</span><span class="n">accs</span><span class="p">)</span><span class="si">:</span><span class="s2">.6f</span><span class="si">}</span><span class="s2">"</span>
    <span class="k">if</span> <span class="n">privacy_engine</span><span class="p">:</span>
        <span class="n">epsilon</span><span class="p">,</span> <span class="n">best_alpha</span> <span class="o">=</span> <span class="n">privacy_engine</span><span class="o">.</span><span class="n">get_privacy_spent</span><span class="p">()</span>
        <span class="n">printstr</span> <span class="o">+=</span> <span class="sa">f</span><span class="s2">" (ε = </span><span class="si">{</span><span class="n">epsilon</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">, δ = </span><span class="si">{</span><span class="n">privacy_engine</span><span class="o">.</span><span class="n">target_delta</span><span class="si">}</span><span class="s2">) for α = </span><span class="si">{</span><span class="n">best_alpha</span><span class="si">}</span><span class="s2">"</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">printstr</span> <span class="o">+</span> <span class="s2">"</span><span class="se">\n</span><span class="s2">----------------------------</span><span class="se">\n</span><span class="s2">"</span><span class="p">)</span>
    <span class="k">return</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Hyper-parameters">Hyper-parameters<a class="anchor-link" href="#Hyper-parameters">¶</a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>There are two sets of hyper-parameters associated with this model. The first are hyper-parameters which we would expect in any machine learning training, such as the learning rate and batch size. The second set are related to the privacy engine, where for example we define the amount of noise added to the gradients (<code>noise_multiplier</code>), and the maximum L2 norm to which the per-sample gradients are clipped (<code>max_grad_norm</code>).</p>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In [9]:</div>
<div class="inner_cell">
<div class="input_area">
<div class="highlight hl-ipython3"><pre><span></span><span class="c1"># Training hyper-parameters</span>
<span class="n">epochs</span> <span class="o">=</span> <span class="mi">50</span>
<span class="n">learning_rate</span> <span class="o">=</span> <span class="mf">2.0</span>

<span class="c1"># Privacy engine hyper-parameters</span>
<span class="n">max_per_sample_grad_norm</span> <span class="o">=</span> <span class="mf">1.5</span>
<span class="n">delta</span> <span class="o">=</span> <span class="mf">8e-5</span>
<span class="n">epsilon</span> <span class="o">=</span> <span class="mf">12.0</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Model">Model<a class="anchor-link" href="#Model">¶</a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>We define the name classification model in the cell below. Note that it is a simple char-LSTM classifier, where the input characters are passed through an <code>nn.Embedding</code> layer, and are subsequently input to the DPLSTM.</p>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In [10]:</div>
<div class="inner_cell">
<div class="input_area">
<div class="highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">from</span> <span class="nn">torch</span> <span class="kn">import</span> <span class="n">nn</span>
<span class="kn">from</span> <span class="nn">opacus.layers</span> <span class="kn">import</span> <span class="n">DPLSTM</span>

<span class="k">class</span> <span class="nc">CharNNClassifier</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">embedding_size</span><span class="p">,</span>
        <span class="n">hidden_size</span><span class="p">,</span>
        <span class="n">output_size</span><span class="p">,</span>
        <span class="n">num_lstm_layers</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">bidirectional</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
        <span class="n">vocab_size</span><span class="o">=</span><span class="n">VOCAB_SIZE</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">embedding_size</span> <span class="o">=</span> <span class="n">embedding_size</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">hidden_size</span> <span class="o">=</span> <span class="n">hidden_size</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">output_size</span> <span class="o">=</span> <span class="n">output_size</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">vocab_size</span> <span class="o">=</span> <span class="n">vocab_size</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">embedding</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Embedding</span><span class="p">(</span><span class="n">vocab_size</span><span class="p">,</span> <span class="n">embedding_size</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">lstm</span> <span class="o">=</span> <span class="n">DPLSTM</span><span class="p">(</span>
            <span class="n">embedding_size</span><span class="p">,</span>
            <span class="n">hidden_size</span><span class="p">,</span>
            <span class="n">num_layers</span><span class="o">=</span><span class="n">num_lstm_layers</span><span class="p">,</span>
            <span class="n">bidirectional</span><span class="o">=</span><span class="n">bidirectional</span><span class="p">,</span>
            <span class="n">batch_first</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">out_layer</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">hidden_size</span><span class="p">,</span> <span class="n">output_size</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">hidden</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">embedding</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>  <span class="c1"># -&gt; [B, T, D]</span>
        <span class="n">x</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">lstm</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">hidden</span><span class="p">)</span>  <span class="c1"># -&gt; [B, T, H]</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="p">[:,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="p">:]</span>  <span class="c1"># -&gt; [B, H]</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">out_layer</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>  <span class="c1"># -&gt; [B, C]</span>
        <span class="k">return</span> <span class="n">x</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>We now proceed to instantiate the objects (privacy engine, model and optimizer) for our differentially-private LSTM training.  However, the <code>nn.LSTM</code> is replaced with a <code>DPLSTM</code> module which enables us to calculate per-example gradients.</p>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In [11]:</div>
<div class="inner_cell">
<div class="input_area">
<div class="highlight hl-ipython3"><pre><span></span><span class="c1"># Set the device to run on a GPU</span>
<span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s2">"cuda"</span> <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="s2">"cpu"</span><span class="p">)</span>

<span class="c1"># Define classifier parameters</span>
<span class="n">embedding_size</span> <span class="o">=</span> <span class="mi">64</span>
<span class="n">hidden_size</span> <span class="o">=</span> <span class="mi">128</span>  <span class="c1"># Number of neurons in hidden layer after LSTM</span>
<span class="n">n_lstm_layers</span> <span class="o">=</span> <span class="mi">1</span>
<span class="n">bidirectional_lstm</span> <span class="o">=</span> <span class="kc">False</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">CharNNClassifier</span><span class="p">(</span>
    <span class="n">embedding_size</span><span class="p">,</span>
    <span class="n">hidden_size</span><span class="p">,</span>
    <span class="nb">len</span><span class="p">(</span><span class="n">ds</span><span class="o">.</span><span class="n">labels</span><span class="p">),</span>
    <span class="n">n_lstm_layers</span><span class="p">,</span>
    <span class="n">bidirectional_lstm</span><span class="p">,</span>
<span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Defining-the-privacy-engine,-optimizer-and-loss-criterion-for-the-problem">Defining the privacy engine, optimizer and loss criterion for the problem<a class="anchor-link" href="#Defining-the-privacy-engine,-optimizer-and-loss-criterion-for-the-problem">¶</a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In [12]:</div>
<div class="inner_cell">
<div class="input_area">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">criterion</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">()</span>
<span class="n">optimizer</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">SGD</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="n">learning_rate</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In [13]:</div>
<div class="inner_cell">
<div class="input_area">
<div class="highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">opacus</span> <span class="kn">import</span> <span class="n">PrivacyEngine</span>

<span class="n">privacy_engine</span> <span class="o">=</span> <span class="n">PrivacyEngine</span><span class="p">(</span>
    <span class="n">model</span><span class="p">,</span>
    <span class="n">sample_rate</span><span class="o">=</span><span class="n">sample_rate</span><span class="p">,</span>
    <span class="n">max_grad_norm</span><span class="o">=</span><span class="n">max_per_sample_grad_norm</span><span class="p">,</span>
    <span class="n">target_delta</span><span class="o">=</span><span class="n">delta</span><span class="p">,</span>
    <span class="n">target_epsilon</span><span class="o">=</span><span class="n">epsilon</span><span class="p">,</span>
    <span class="n">epochs</span><span class="o">=</span><span class="n">epochs</span><span class="p">,</span>
    <span class="n">secure_rng</span><span class="o">=</span><span class="n">secure_rng</span><span class="p">,</span>
<span class="p">)</span>
<span class="n">privacy_engine</span><span class="o">.</span><span class="n">attach</span><span class="p">(</span><span class="n">optimizer</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="output_wrapper">
<div class="output">
<div class="output_area">
<div class="prompt"></div>
<div class="output_subarea output_stream output_stderr output_text">
<pre>/private/home/asablayrolles/code/projects/opacus/opacus/privacy_engine.py:120: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.
  "Secure RNG turned off. This is perfectly fine for experimentation as it allows "
</pre>
</div>
</div>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Training-the-name-classifier-with-privacy">Training the name classifier with privacy<a class="anchor-link" href="#Training-the-name-classifier-with-privacy">¶</a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Finally we can start training ! We will be training for 50 epochs iterations (where each epoch corresponds to a pass over the whole dataset). We will be reporting the privacy epsilon every <code>test_every</code> epochs. We will also benchmark this differentially-private model against a model without privacy and obtain almost identical performance. Further, the private model trained with Opacus incurs only minimal overhead in training time, with the differentially-private classifier only slightly slower (by a couple of minutes) than the non-private model.</p>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In [14]:</div>
<div class="inner_cell">
<div class="input_area">
<div class="highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">tqdm</span> <span class="kn">import</span> <span class="n">tqdm</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">"Train stats: </span><span class="se">\n</span><span class="s2">"</span><span class="p">)</span>
<span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="n">tqdm</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">epochs</span><span class="p">)):</span>
    <span class="n">train</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">criterion</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">train_loader</span><span class="p">,</span> <span class="n">epoch</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">test_every</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">epoch</span> <span class="o">%</span> <span class="n">test_every</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">test</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">test_loader</span><span class="p">,</span> <span class="n">privacy_engine</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>

<span class="n">test</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">test_loader</span><span class="p">,</span> <span class="n">privacy_engine</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="output_wrapper">
<div class="output">
<div class="output_area">
<div class="prompt"></div>
<div class="output_subarea output_stream output_stdout output_text">
<pre>Train stats: 

	 Epoch 0. Accuracy: 0.429625 | Loss: 2.185477 | (ε = 2.59, δ = 8e-05) for α = 5.6

----------------------------
Test Accuracy: 0.470559 (ε = 2.59, δ = 8e-05) for α = 5.6
----------------------------

	 Epoch 1. Accuracy: 0.468625 | Loss: 1.940962 | (ε = 3.07, δ = 8e-05) for α = 5.2
	 Epoch 2. Accuracy: 0.468188 | Loss: 1.928116 | (ε = 3.46, δ = 8e-05) for α = 5.0
	 Epoch 3. Accuracy: 0.468250 | Loss: 1.907378 | (ε = 3.81, δ = 8e-05) for α = 4.8
	 Epoch 4. Accuracy: 0.477125 | Loss: 1.833195 | (ε = 4.12, δ = 8e-05) for α = 4.6
	 Epoch 5. Accuracy: 0.538125 | Loss: 1.566213 | (ε = 4.41, δ = 8e-05) for α = 4.5

----------------------------
Test Accuracy: 0.552575 (ε = 4.41, δ = 8e-05) for α = 4.5
----------------------------

	 Epoch 6. Accuracy: 0.556937 | Loss: 1.512054 | (ε = 4.67, δ = 8e-05) for α = 4.3
	 Epoch 7. Accuracy: 0.562937 | Loss: 1.503791 | (ε = 4.93, δ = 8e-05) for α = 4.2
	 Epoch 8. Accuracy: 0.563813 | Loss: 1.510231 | (ε = 5.17, δ = 8e-05) for α = 4.1
	 Epoch 9. Accuracy: 0.568250 | Loss: 1.504014 | (ε = 5.41, δ = 8e-05) for α = 4.0
	 Epoch 10. Accuracy: 0.571063 | Loss: 1.497570 | (ε = 5.63, δ = 8e-05) for α = 3.9

----------------------------
Test Accuracy: 0.574104 (ε = 5.63, δ = 8e-05) for α = 3.9
----------------------------

	 Epoch 11. Accuracy: 0.576250 | Loss: 1.489521 | (ε = 5.85, δ = 8e-05) for α = 3.9
	 Epoch 12. Accuracy: 0.580812 | Loss: 1.485841 | (ε = 6.06, δ = 8e-05) for α = 3.8
	 Epoch 13. Accuracy: 0.589063 | Loss: 1.482238 | (ε = 6.27, δ = 8e-05) for α = 3.7
	 Epoch 14. Accuracy: 0.604000 | Loss: 1.459263 | (ε = 6.46, δ = 8e-05) for α = 3.7
	 Epoch 15. Accuracy: 0.622437 | Loss: 1.423232 | (ε = 6.66, δ = 8e-05) for α = 3.6

----------------------------
Test Accuracy: 0.630179 (ε = 6.66, δ = 8e-05) for α = 3.6
----------------------------

	 Epoch 16. Accuracy: 0.633563 | Loss: 1.397400 | (ε = 6.85, δ = 8e-05) for α = 3.6
	 Epoch 17. Accuracy: 0.647188 | Loss: 1.359415 | (ε = 7.03, δ = 8e-05) for α = 3.5
	 Epoch 18. Accuracy: 0.659375 | Loss: 1.327021 | (ε = 7.22, δ = 8e-05) for α = 3.5
	 Epoch 19. Accuracy: 0.668937 | Loss: 1.309529 | (ε = 7.39, δ = 8e-05) for α = 3.4
	 Epoch 20. Accuracy: 0.668500 | Loss: 1.327612 | (ε = 7.57, δ = 8e-05) for α = 3.4

----------------------------
Test Accuracy: 0.649833 (ε = 7.57, δ = 8e-05) for α = 3.4
----------------------------

	 Epoch 21. Accuracy: 0.672687 | Loss: 1.296074 | (ε = 7.74, δ = 8e-05) for α = 3.4
	 Epoch 22. Accuracy: 0.681250 | Loss: 1.267687 | (ε = 7.91, δ = 8e-05) for α = 3.3
	 Epoch 23. Accuracy: 0.684500 | Loss: 1.268492 | (ε = 8.07, δ = 8e-05) for α = 3.3
	 Epoch 24. Accuracy: 0.693063 | Loss: 1.245834 | (ε = 8.24, δ = 8e-05) for α = 3.3
	 Epoch 25. Accuracy: 0.698000 | Loss: 1.233152 | (ε = 8.40, δ = 8e-05) for α = 3.2

----------------------------
Test Accuracy: 0.691701 (ε = 8.40, δ = 8e-05) for α = 3.2
----------------------------

	 Epoch 26. Accuracy: 0.698812 | Loss: 1.231949 | (ε = 8.56, δ = 8e-05) for α = 3.2
	 Epoch 27. Accuracy: 0.701313 | Loss: 1.222030 | (ε = 8.72, δ = 8e-05) for α = 3.2
	 Epoch 28. Accuracy: 0.707562 | Loss: 1.209349 | (ε = 8.87, δ = 8e-05) for α = 3.1
	 Epoch 29. Accuracy: 0.708750 | Loss: 1.213605 | (ε = 9.02, δ = 8e-05) for α = 3.1
	 Epoch 30. Accuracy: 0.713750 | Loss: 1.192162 | (ε = 9.17, δ = 8e-05) for α = 3.1

----------------------------
Test Accuracy: 0.707720 (ε = 9.17, δ = 8e-05) for α = 3.1
----------------------------

	 Epoch 31. Accuracy: 0.719562 | Loss: 1.166927 | (ε = 9.32, δ = 8e-05) for α = 3.1
	 Epoch 32. Accuracy: 0.718938 | Loss: 1.181886 | (ε = 9.47, δ = 8e-05) for α = 3.0
	 Epoch 33. Accuracy: 0.724938 | Loss: 1.163102 | (ε = 9.62, δ = 8e-05) for α = 3.0
	 Epoch 34. Accuracy: 0.724000 | Loss: 1.162879 | (ε = 9.76, δ = 8e-05) for α = 3.0
	 Epoch 35. Accuracy: 0.726375 | Loss: 1.164932 | (ε = 9.90, δ = 8e-05) for α = 3.0

----------------------------
Test Accuracy: 0.702265 (ε = 9.90, δ = 8e-05) for α = 3.0
----------------------------

	 Epoch 36. Accuracy: 0.721313 | Loss: 1.173956 | (ε = 10.05, δ = 8e-05) for α = 3.0
	 Epoch 37. Accuracy: 0.735437 | Loss: 1.122051 | (ε = 10.19, δ = 8e-05) for α = 2.9
	 Epoch 38. Accuracy: 0.736687 | Loss: 1.125166 | (ε = 10.32, δ = 8e-05) for α = 2.9
	 Epoch 39. Accuracy: 0.736500 | Loss: 1.140181 | (ε = 10.46, δ = 8e-05) for α = 2.9
	 Epoch 40. Accuracy: 0.734750 | Loss: 1.132542 | (ε = 10.60, δ = 8e-05) for α = 2.9

----------------------------
Test Accuracy: 0.715653 (ε = 10.60, δ = 8e-05) for α = 2.9
----------------------------

	 Epoch 41. Accuracy: 0.734875 | Loss: 1.125319 | (ε = 10.74, δ = 8e-05) for α = 2.9
	 Epoch 42. Accuracy: 0.739062 | Loss: 1.114325 | (ε = 10.87, δ = 8e-05) for α = 2.8
	 Epoch 43. Accuracy: 0.740750 | Loss: 1.111604 | (ε = 11.00, δ = 8e-05) for α = 2.8
	 Epoch 44. Accuracy: 0.740125 | Loss: 1.099650 | (ε = 11.13, δ = 8e-05) for α = 2.8
	 Epoch 45. Accuracy: 0.750812 | Loss: 1.062885 | (ε = 11.26, δ = 8e-05) for α = 2.8

----------------------------
Test Accuracy: 0.739057 (ε = 11.26, δ = 8e-05) for α = 2.8
----------------------------

	 Epoch 46. Accuracy: 0.749750 | Loss: 1.076617 | (ε = 11.40, δ = 8e-05) for α = 2.8
	 Epoch 47. Accuracy: 0.749437 | Loss: 1.091281 | (ε = 11.53, δ = 8e-05) for α = 2.8
	 Epoch 48. Accuracy: 0.751625 | Loss: 1.067713 | (ε = 11.66, δ = 8e-05) for α = 2.8
	 Epoch 49. Accuracy: 0.752250 | Loss: 1.067498 | (ε = 11.78, δ = 8e-05) for α = 2.7

----------------------------
Test Accuracy: 0.732004 (ε = 11.78, δ = 8e-05) for α = 2.7
----------------------------

</pre>
</div>
</div>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>The differentially-private name classification model obtains a test accuracy of 0.73 with an epsilon of just under 12. This shows that we can achieve a good accuracy on this task, with minimal loss of privacy.</p>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Training-the-name-classifier-without-privacy">Training the name classifier without privacy<a class="anchor-link" href="#Training-the-name-classifier-without-privacy">¶</a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>We also run a comparison with a non-private model to see if the performance obtained with privacy is comparable to it. To do this, we keep the parameters such as learning rate and batch size the same, and only define a different instance of the model along with a separate optimizer.</p>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In [17]:</div>
<div class="inner_cell">
<div class="input_area">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">model_nodp</span> <span class="o">=</span> <span class="n">CharNNClassifier</span><span class="p">(</span>
    <span class="n">embedding_size</span><span class="p">,</span>
    <span class="n">hidden_size</span><span class="p">,</span>
    <span class="nb">len</span><span class="p">(</span><span class="n">ds</span><span class="o">.</span><span class="n">labels</span><span class="p">),</span>
    <span class="n">n_lstm_layers</span><span class="p">,</span>
    <span class="n">bidirectional_lstm</span><span class="p">,</span>
<span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>


<span class="n">optimizer_nodp</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">SGD</span><span class="p">(</span><span class="n">model_nodp</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In [18]:</div>
<div class="inner_cell">
<div class="input_area">
<div class="highlight hl-ipython3"><pre><span></span><span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="n">tqdm</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">epochs</span><span class="p">)):</span>
    <span class="n">train</span><span class="p">(</span><span class="n">model_nodp</span><span class="p">,</span> <span class="n">criterion</span><span class="p">,</span> <span class="n">optimizer_nodp</span><span class="p">,</span> <span class="n">train_loader</span><span class="p">,</span> <span class="n">epoch</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">test_every</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">epoch</span> <span class="o">%</span> <span class="n">test_every</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">test</span><span class="p">(</span><span class="n">model_nodp</span><span class="p">,</span> <span class="n">test_loader</span><span class="p">,</span> <span class="kc">None</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>

<span class="n">test</span><span class="p">(</span><span class="n">model_nodp</span><span class="p">,</span> <span class="n">test_loader</span><span class="p">,</span> <span class="kc">None</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="output_wrapper">
<div class="output">
<div class="output_area">
<div class="prompt"></div>
<div class="output_subarea output_stream output_stdout output_text">
<pre>	 Epoch 0. Accuracy: 0.446188 | Loss: 1.975067

----------------------------
Test Accuracy: 0.470559
----------------------------

	 Epoch 1. Accuracy: 0.468625 | Loss: 1.851975
	 Epoch 2. Accuracy: 0.468438 | Loss: 1.851132
	 Epoch 3. Accuracy: 0.468750 | Loss: 1.860505
	 Epoch 4. Accuracy: 0.469000 | Loss: 1.852566
	 Epoch 5. Accuracy: 0.468500 | Loss: 1.851430

----------------------------
Test Accuracy: 0.470559
----------------------------

	 Epoch 6. Accuracy: 0.467375 | Loss: 1.847835
	 Epoch 7. Accuracy: 0.498937 | Loss: 1.702268
	 Epoch 8. Accuracy: 0.540625 | Loss: 1.550873
	 Epoch 9. Accuracy: 0.551125 | Loss: 1.507487
	 Epoch 10. Accuracy: 0.556312 | Loss: 1.488815

----------------------------
Test Accuracy: 0.558185
----------------------------

	 Epoch 11. Accuracy: 0.560312 | Loss: 1.477035
	 Epoch 12. Accuracy: 0.563562 | Loss: 1.456275
	 Epoch 13. Accuracy: 0.561875 | Loss: 1.466037
	 Epoch 14. Accuracy: 0.569187 | Loss: 1.442874
	 Epoch 15. Accuracy: 0.570063 | Loss: 1.443760

----------------------------
Test Accuracy: 0.571025
----------------------------

	 Epoch 16. Accuracy: 0.581313 | Loss: 1.416902
	 Epoch 17. Accuracy: 0.613812 | Loss: 1.352785
	 Epoch 18. Accuracy: 0.623250 | Loss: 1.322635
	 Epoch 19. Accuracy: 0.636062 | Loss: 1.275303
	 Epoch 20. Accuracy: 0.643125 | Loss: 1.246226

----------------------------
Test Accuracy: 0.655041
----------------------------

	 Epoch 21. Accuracy: 0.655000 | Loss: 1.214294
	 Epoch 22. Accuracy: 0.658250 | Loss: 1.188098
	 Epoch 23. Accuracy: 0.667500 | Loss: 1.159147
	 Epoch 24. Accuracy: 0.679438 | Loss: 1.136272
	 Epoch 25. Accuracy: 0.687438 | Loss: 1.102815

----------------------------
Test Accuracy: 0.695590
----------------------------

	 Epoch 26. Accuracy: 0.686562 | Loss: 1.093785
	 Epoch 27. Accuracy: 0.688063 | Loss: 1.083488
	 Epoch 28. Accuracy: 0.697000 | Loss: 1.054640
	 Epoch 29. Accuracy: 0.702250 | Loss: 1.028159
	 Epoch 30. Accuracy: 0.706187 | Loss: 1.015101

----------------------------
Test Accuracy: 0.682311
----------------------------

	 Epoch 31. Accuracy: 0.701688 | Loss: 1.024621
	 Epoch 32. Accuracy: 0.707500 | Loss: 1.002122
	 Epoch 33. Accuracy: 0.716375 | Loss: 0.976570
	 Epoch 34. Accuracy: 0.719875 | Loss: 0.966798
	 Epoch 35. Accuracy: 0.720125 | Loss: 0.964287

----------------------------
Test Accuracy: 0.695451
----------------------------

	 Epoch 36. Accuracy: 0.719375 | Loss: 0.954905
	 Epoch 37. Accuracy: 0.728688 | Loss: 0.932315
	 Epoch 38. Accuracy: 0.731250 | Loss: 0.928614
	 Epoch 39. Accuracy: 0.741875 | Loss: 0.894388
	 Epoch 40. Accuracy: 0.737875 | Loss: 0.901502

----------------------------
Test Accuracy: 0.744666
----------------------------

	 Epoch 41. Accuracy: 0.747875 | Loss: 0.869028
	 Epoch 42. Accuracy: 0.741750 | Loss: 0.880296
	 Epoch 43. Accuracy: 0.740563 | Loss: 0.890370
	 Epoch 44. Accuracy: 0.751375 | Loss: 0.849146
	 Epoch 45. Accuracy: 0.750125 | Loss: 0.851319

----------------------------
Test Accuracy: 0.757715
----------------------------

	 Epoch 46. Accuracy: 0.754750 | Loss: 0.838435
	 Epoch 47. Accuracy: 0.756875 | Loss: 0.828314
	 Epoch 48. Accuracy: 0.763813 | Loss: 0.809650
	 Epoch 49. Accuracy: 0.763750 | Loss: 0.806187

----------------------------
Test Accuracy: 0.751958
----------------------------

</pre>
</div>
</div>
<div class="output_area">
<div class="prompt"></div>
<div class="output_subarea output_stream output_stderr output_text">
<pre>
</pre>
</div>
</div>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>We run the training loop again, this time without privacy and for the same number of iterations.</p>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>The non-private classifier obtains a test accuracy of around 0.75 with the same parameters and number of epochs. We are effectively trading off performance on the name classification task for a lower loss of privacy.</p>
</div>
</div>
</div>
</div></div><div class="tutorialButtonWrapper buttonWrapper"><a class="tutorialButton button" download="" href="https://github.com/pytorch/opacus/blob/master/tutorials/building_lstm_name_classifier.ipynb" target="_blank"><svg aria-hidden="true" focusable="false" data-prefix="fas" data-icon="file-download" class="svg-inline--fa fa-file-download fa-w-12" role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 384 512"><path fill="currentColor" d="M224 136V0H24C10.7 0 0 10.7 0 24v464c0 13.3 10.7 24 24 24h336c13.3 0 24-10.7 24-24V160H248c-13.2 0-24-10.8-24-24zm76.45 211.36l-96.42 95.7c-6.65 6.61-17.39 6.61-24.04 0l-96.42-95.7C73.42 337.29 80.54 320 94.82 320H160v-80c0-8.84 7.16-16 16-16h32c8.84 0 16 7.16 16 16v80h65.18c14.28 0 21.4 17.29 11.27 27.36zM377 105L279.1 7c-4.5-4.5-10.6-7-17-7H256v128h128v-6.1c0-6.3-2.5-12.4-7-16.9z"></path></svg>Download Tutorial Jupyter Notebook</a></div></div></div></div><footer class="nav-footer" id="footer"><section class="sitemap"><a href="/" class="nav-home"><img src="/img/opacus_favicon.svg" alt="Opacus" width="66" height="58"/></a><div class="footerSection"><h5>Docs</h5><a href="/docs/introduction">Introduction</a><a href="/docs/faq">FAQ</a><a href="/tutorials/">Tutorials</a><a href="/api/">API Reference</a></div><div class="footerSection"><h5>Social</h5><div class="social"><a class="github-button" href="https://github.com/pytorch/opacus" data-count-href="https://github.com/pytorch/opacus/stargazers" data-show-count="true" data-count-aria-label="# stargazers on GitHub" aria-label="Star Opacus on GitHub">opacus</a></div></div><div class="footerSection"><h5>Legal</h5><a href="https://opensource.facebook.com/legal/privacy/" target="_blank" rel="noreferrer noopener">Privacy</a><a href="https://opensource.facebook.com/legal/terms/" target="_blank" rel="noreferrer noopener">Terms</a></div></section><a href="https://opensource.facebook.com/" target="_blank" rel="noreferrer noopener" class="fbOpenSource"><img src="/img/oss_logo.png" alt="Facebook Open Source" width="170" height="45"/></a><section class="copyright"> Copyright © 2021 Facebook Inc.</section></footer></div><script type="text/javascript" src="https://cdn.jsdelivr.net/docsearch.js/1/docsearch.min.js"></script><script>
                document.addEventListener('keyup', function(e) {
                  if (e.target !== document.body) {
                    return;
                  }
                  // keyCode for '/' (slash)
                  if (e.keyCode === 191) {
                    const search = document.getElementById('search_input_react');
                    search && search.focus();
                  }
                });
              </script><script>
              var search = docsearch({
                
                apiKey: '207c27d819f967749142d8611de7cb19',
                indexName: 'opacus',
                inputSelector: '#search_input_react'
              });
            </script></body></html>